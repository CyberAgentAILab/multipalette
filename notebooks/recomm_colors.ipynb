{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cedc18c0-1b26-4d12-974b-22173a9e5851",
   "metadata": {},
   "source": [
    "### This a tutorial of color recommendation for json files.\n",
    "Process:\n",
    "- Step1: Extract the color palettes of Image-SVG-Text elements from json file, show multiple palettes and design image\n",
    "- Step2: Get the recommended colors for a specified color in a specified palette\n",
    "** If you want to check the recolored results with the recommended colors, please check the video of our prototype system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c839df40-1a36-481d-8246-53636ef66c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !python3 -m pip install tensorflow-cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0eae829-5fba-47b4-9b4d-b65c3f3def33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import io\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "import time\n",
    "from operator import itemgetter, attrgetter\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import Image as ipyImage\n",
    "from ipycanvas import Canvas\n",
    "from base64 import b64encode, b64decode\n",
    "import pandas as pd\n",
    "from collections import defaultdict  # For word frequency\n",
    "import math\n",
    "import random\n",
    "import ast\n",
    "\n",
    "import sys\n",
    "sys.path.append('../src')\n",
    "\n",
    "from multipalette.utils.color_convertor import lab_to_rgb, rgb_to_lab, range0to255, imageRGBA2LAB\n",
    "from multipalette.preprocess.color_extractor import get_colors\n",
    "from multipalette.colorbert.input_data_generator import DataGenerator\n",
    "from multipalette.colorbert.model_config import Config\n",
    "\n",
    "# reset the sample url to check different samples\n",
    "sample_url = '../data/model_test_input/crello_samples/json_sample_2.json'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd5ae77-3125-499c-a293-cd7bae0c8fa8",
   "metadata": {},
   "source": [
    "## Extract the color palettes of Image-SVG-Text elements\n",
    "- Convert image data RGB to CIELab\n",
    "- Use Kmeans clustering in sklearn (kmeans in faiss can be faster, while the result is a little different)\n",
    "- Check the extracted colors by converting Lab to RGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6206924-5065-4fdc-9842-cf74002ab8b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reshape image as [w*h, 3] to concate multiple images\n",
    "def reshape_image(pil_image):\n",
    "    image = np.array(pil_image)\n",
    "    # remove the 4th channel of image\n",
    "    if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "        #convert the image from RGBA2RGB\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGRA2BGR) # Alpha channel may should be concerned in future work\n",
    "    image = image.reshape((image.shape[0] * image.shape[1], 3))\n",
    "    return image\n",
    "\n",
    "# draw palette without color rate\n",
    "def draw_palette(colors):\n",
    "    palette = np.zeros((50, 300, 3), dtype = \"uint8\")\n",
    "    startX = 0\n",
    "    for c in range(len(colors)):\n",
    "        endX = startX + (1 / len(colors) * 300)\n",
    "        cv2.rectangle(palette, (int(startX), 0), (int(endX), 50), colors[c], -1)\n",
    "        startX = endX\n",
    "    # draw border line for easy check in light gray #D3D3D3 \n",
    "    cv2.rectangle(palette, (0, 0), (300, 50), (211, 211, 211), 2)\n",
    "    plt.imshow(palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "837ed683-32bb-4082-a973-914f3c7e639c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../src/multipalette/preprocess/color_extractor.py:20: ConvergenceWarning: Number of distinct clusters (4) found smaller than n_clusters (5). Possibly due to duplicate points in X.\n",
      "  # cluster the pixel intensities\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image palette:\n",
      "RGB data: [[52, 109, 120], [56, 93, 96], [178, 147, 108], [240, 238, 234], [59, 57, 51]]\n",
      "Lab data: [[109, 113, 116], [94, 116, 122], [160, 134, 153], [240, 128, 130], [61, 128, 132]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAACAUlEQVR4nO3aMY7TQBiG4XESJ3YaRImQKJAQjTsKLsChoOEKXAK4AuUWuYLPACtEQxIB0aKYio5kg9h82SXP085o/EeyX1lWqmEYCgAZo1MPAHBORBcgSHQBgkQXIEh0AYJEFyBosm+x73v/JwP4S13XVbvWvOkCBO190/3tzYeL8mW1PvYs3GHV1aaMfqxOPcbZefFoVh7fG596jH/y4Mmz8vDp89j13r1/WxaLxVHObpqmvHz1eu+eg6L7ebkul1+XNzIU/6dq862Mv7tH0tb3m3JVH/QY31rDz02pg79htVyWy08fj3J227bX7vF5ASBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCJodsaqd1mU/rY8/CHVaVWRlvZ6ce4+zU9bSMJgc9xrdWNRqX7XYbu149nZZ2Pj/K2W3TXrunGoZh52Lf97sXAfijruuqXWt7owvAzfJNFyBIdAGCRBcgSHQBgkQXIEh0AYJ+AbNFOlXzzKAaAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVG palette:\n",
      "RGB data: [[36, 30, 32], [187, 147, 101], [24, 66, 64]]\n",
      "Lab data: [[31, 131, 128], [162, 137, 158], [64, 113, 125]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAByklEQVR4nO3aMU7cUBSG0WsYgceTFNkAK3CVvbAMGpQuTSJlB9lPVuENEAUxtOkohkdFOYZI+LdEzmnfLa5dfLKe3LXWCoCMk7UXAPifiC5AkOgCBIkuQJDoAgSJLkDQZu5wmib/kwH8o3Ecu2NnvnQBgma/dJ/9+Pa97vf3S+8CVNXV5ef69LFfe43FfP11U4fHtbdYxtCf18/rL7Mzr4ru/u6ubv/cvslSwLyHvxd1OB3WXmMRrbX6vd/X4Z1eXO767YszrhcAgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIEh0AYJEFyBIdAGCRBcgSHQBgkQXIGjzmqHtMNRut1t6F6CqTs/66jbna6+xiK6qPgxDHR7b2qssYui3L850rR1/+Gma3uebAVjQOI7dsbPZ6ALwttzpAgSJLkCQ6AIEiS5AkOgCBIkuQNATJh0wWPynWdMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text palette:\n",
      "RGB data: [[203, 193, 128], [255, 255, 255]]\n",
      "Lab data: [[198, 122, 162], [255, 128, 128]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABm0lEQVR4nO3asUrDUACF4ZtaMZuTgvgKHcUH8N19g0C3vkIH6yLcXAfp0MGaYj0R+n2QKXc4Q/gJIV1rrQCQsZh7AMAlEV2AINEFCBJdgCDRBQgSXYCg5bGbwzD4nwzgRKvVqvvunjddgKCjb7p7H2+vpdX3v94Ck90/Ppe7h6e5Z8CBcRzLZrM5emZSdFvdlTbuzjIKzuFqUUvf93PPgAO11h/P+LwAECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEHLSae6668L/onWulJrnXsGHJjyTE6K7s3ty6/HwDltd6Vs1+u5Z8DJutba3BsALoZvugBBogsQJLoAQaILECS6AEGiCxD0CRKpLVIvAIIMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c34f2a693acf4ca48f5544bb01f7405f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(height=788, sync_image_data=True, width=940)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load json file and show multiple palettes of Image-SVG-Text elements and the whole design image\n",
    "\n",
    "with open(sample_url) as json_file:\n",
    "    example = json.load(json_file)\n",
    "\n",
    "    canvas_width = example['canvas_width']\n",
    "    canvas_height = example['canvas_height']\n",
    "    # draw all elements in canvas\n",
    "    canvas = Canvas(width=canvas_width, height=canvas_height, sync_image_data=True)\n",
    "\n",
    "    # initial image_list, svg_list, text_list\n",
    "    image_list = []\n",
    "    svg_list = []\n",
    "    text_list = []\n",
    "    text_size = []\n",
    "\n",
    "    for i in range(len(example['types'])):\n",
    "        layer = example[f'element_{i}']\n",
    "        # if example['type'][i] != b'textElement':\n",
    "        x = layer['left']*canvas_width\n",
    "        y = layer['top']*canvas_height\n",
    "        width = layer['width']*canvas_width\n",
    "        height = layer['height']*canvas_height\n",
    "        color_rgb = layer['color']\n",
    "        color_hex = '#%02x%02x%02x' % (color_rgb[0], color_rgb[1], color_rgb[2])\n",
    "\n",
    "        # reconstruct canvas to check\n",
    "        image = ipyImage.from_file(io.BytesIO(b64decode(layer['image_bytes'])))\n",
    "        canvas.draw_image(image, x, y, width, height)    \n",
    "\n",
    "        if example['types'][i] == 'imageElement' or example['types'][i] == 'maskElement':\n",
    "            image_pil = Image.open(io.BytesIO(b64decode(layer['image_bytes'])))\n",
    "            image_list.append(reshape_image(imageRGBA2LAB(image_pil)))\n",
    "\n",
    "        if example['types'][i] == 'svgElement' or example['types'][i] == 'coloredBackground':\n",
    "            svg_pil = Image.open(io.BytesIO(b64decode(layer['image_bytes'])))\n",
    "            svg_list.append(reshape_image(imageRGBA2LAB(svg_pil)))\n",
    "\n",
    "        if example['types'][i] == 'textElement':\n",
    "            canvas.font = f'{height}px sans-serif'\n",
    "            canvas.stroke_style = color_hex\n",
    "            canvas.fill_style = color_hex\n",
    "            canvas.fill_text('TEXT', x, y+height)\n",
    "            canvas.stroke_rect(x, y, width, height)\n",
    "            if [color_rgb[0], color_rgb[1], color_rgb[2]] not in text_list:\n",
    "                text_list.append([color_rgb[0], color_rgb[1], color_rgb[2]])\n",
    "                text_size.append(width * height)\n",
    "\n",
    "    for i in range(len(image_list)):\n",
    "        if i == 0:\n",
    "            image_np = image_list[i]\n",
    "        else:\n",
    "            image_np = np.concatenate((image_np, image_list[i]), axis=0)\n",
    "\n",
    "    for i in range(len(svg_list)):\n",
    "        if i == 0:\n",
    "            svg_np = svg_list[i]\n",
    "        else:\n",
    "            svg_np = np.concatenate((svg_np, svg_list[i]), axis=0)\n",
    "\n",
    "    # sort text color list by text area size\n",
    "    text_list = [x for _, x in sorted(zip(text_size, text_list), reverse=True)]\n",
    "    if len(text_list) > 5:\n",
    "        text_np = np.array(text_list)\n",
    "        (text_colors, text_colors_lab, text_color_rates, text_palette) = get_colors(text_np, 5)\n",
    "    else:\n",
    "        text_colors = text_list\n",
    "        text_colors_lab = [rgb_to_lab(rgb) for rgb in text_list]\n",
    "\n",
    "\n",
    "    if len(image_list) > 0:\n",
    "        # image_np = reduce_color_bins(image_np)\n",
    "        (image_colors, image_colors_lab, image_color_rates, image_palette) = get_colors(image_np, 5)\n",
    "    if len(svg_list) > 0:\n",
    "        # svg_np = reduce_color_bins(svg_np)\n",
    "        (svg_colors, svg_colors_lab, svg_color_rates, svg_palette) = get_colors(svg_np, 5)\n",
    "    # if len(text_list) > 0:\n",
    "    #     print(text_colors)\n",
    "\n",
    "    print('Image palette:')\n",
    "    print(f'RGB data: {image_colors}')\n",
    "    print(f'Lab data: {image_colors_lab}')\n",
    "    # print(f'Color rates: {image_color_rates}')\n",
    "    plt.imshow(image_palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print('SVG palette:')\n",
    "    print(f'RGB data: {svg_colors}')\n",
    "    print(f'Lab data: {svg_colors_lab}')\n",
    "    # print(f'Color rates: {svg_color_rates}')\n",
    "    plt.imshow(svg_palette)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    print('Text palette:')\n",
    "    print(f'RGB data: {text_colors}')\n",
    "    print(f'Lab data: {text_colors_lab}')\n",
    "    draw_palette(text_colors)\n",
    "\n",
    "canvas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c562c4a-90bc-4e51-8ff6-be772ad50cc3",
   "metadata": {},
   "source": [
    "## Get the recommended colors for a specified color in a specified palette\n",
    "### Prepare the color dataset for BERT input\n",
    "- Color sequance of multiple palettes: image colors (max 5), svg colors (max 5), text colors (max 5)\n",
    "- Color corpus: assign color in a b×b×b histogram/bin (b=16 in this work)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f1ab061-25f3-4a83-b539-8d88dd613976",
   "metadata": {},
   "source": [
    "### Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "31a1a1b6-96c1-494c-a3d3-1c93b12b1873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:SavedModel saved prior to TF 2.5 detected when loading Keras model. Please ensure that you are saving the model with model.save() or tf.keras.models.save_model(), *NOT* tf.saved_model.save(). To confirm, there should be a file named \"keras_metadata.pb\" in the SavedModel directory.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-09-27 14:07:35.633820: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in save file, so the model was *not* compiled. Compile it manually.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "re_model = tf.keras.models.load_model(f\"../data/trained_models/bert_lab_bins_16_0.1_0.3_nop_2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "032e26a1-c08e-4e62-9474-43cbd6ae9128",
   "metadata": {},
   "source": [
    "### Set input palettes and denote the masked position manually by setting maskColors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f221b906-3b75-4d9c-bb12-b97520a8c1b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# input rgb\n",
    "input_palettes = {\n",
    "    'image': image_colors,\n",
    "    'svg': svg_colors,\n",
    "    'text': text_colors,\n",
    "}\n",
    "\n",
    "# 1 denotes mask\n",
    "maskColors = {\n",
    "    'image': '[0,0,0,0,0]',\n",
    "    'svg': '[0,1,0]',\n",
    "    'text': '[0,0]',\n",
    "}\n",
    "volumns = ['image', 'svg', 'text']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00535fe1-f760-4edd-a240-54e786a0ed8d",
   "metadata": {},
   "source": [
    "### Predict the masked color and show top10 results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a659537c-0732-4372-9069-eda6afb09976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original palettes: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAAB9klEQVR4nO3bS27TUBTH4XNbt4nDVsyIZbANBjw2ABO2wHIYsolsgYdQhdQHA4TkywSGSQtq/w7K9019B0dHys+W5bTeewGQcbL0AADHRHQBgkQXIEh0AYJEFyBIdAGChn0Xt9ut78kA/tI0TW3XNU+6AEF7n3T/ePf+Q11c3zz0LAft9Ppi6REOQquqZ483tfM2fkxaqydPn1ezjeq918tXL+rY/2y1Xq/r9Zu3e8/cKbpfr27qy+XVvQz1X+q9Ti+/+Wn99vP7j2rNNqqqzobBLqpqnuf6/Onj0mMsbhzHW894vQAQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQcNdDo3nZ7U5P3voWQ7asFotPcJhaFUnw6paW3qQQ9BqnudqllHz3GuzeVS9+tKjLGpcj7eeab3vXtJ2uz3uDQL8g2madt6J90YXgPvlnS5AkOgCBIkuQJDoAgSJLkCQ6AIE/QJqSj1D3Vb7TQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABw0lEQVR4nO3aPUrEUACF0RcdMJMRsbSwtJKsw0W4DHEBCu7A2jXZpLMTxRnEVm0kVnbOL+NN4Tnte8WFwEcIqfq+LwBk7Aw9AOA/EV2AINEFCBJdgCDRBQgSXYCg0aLDruv8TwawprZtq3ln3nQBgha+6f64ubous+nsr7ewRSfHh+X87HToGWzo7n5WHt4+h57Bmpp6r9xeXC68s1J0py8v5fnpeSujyDjYfS9f70dDz2BD09dZeXz9GHoGa5rU46V3fF4ACBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgCDRBQgSXYAg0QUIEl2AINEFCBJdgKDRKpfGTVMmk8lfb2GL6qYp1Whv6BlsqKnHZX889ArW1dTLH1rV9/3cw67r5h8C8Ku2bat5ZwujC8B2+aYLECS6AEGiCxAkugBBogsQJLoAQd9hCyxMBYFVhgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABm0lEQVR4nO3asUrDUACF4ZtaMZuTgvgKHcUH8N19g0C3vkIH6yLcXAfp0MGaYj0R+n2QKXc4Q/gJIV1rrQCQsZh7AMAlEV2AINEFCBJdgCDRBQgSXYCg5bGbwzD4nwzgRKvVqvvunjddgKCjb7p7H2+vpdX3v94Ck90/Ppe7h6e5Z8CBcRzLZrM5emZSdFvdlTbuzjIKzuFqUUvf93PPgAO11h/P+LwAECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEGiCxAkugBBogsQJLoAQaILECS6AEHLSae6668L/onWulJrnXsGHJjyTE6K7s3ty6/HwDltd6Vs1+u5Z8DJutba3BsALoZvugBBogsQJLoAQaILECS6AEGiCxD0CRKpLVIvAIIMAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mask position: 1 denotes mask\n",
      "{'image': '[0,0,0,0,0]', 'svg': '[0,1,0]', 'text': '[0,0]'}\n",
      "Recommended results: \n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABaklEQVR4nO3aPU5CQRSA0XmGZ+VS2AirdhOsxJ/KhLGyFDDKR5Bz2rnFrb5MJrPMOQcAjYdrLwBwT0QXICS6ACHRBQiJLkBIdAFCm2OH+/3efzKAH9put8t3Z266AKGjN90vH+/PYx7eLr0LwE1bls1Yn3ZHZ86K7jy8jnF4+ZOlAP6rOdaTM54XAEKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxDanDO0LOuYY730LgC3bXk8OXJWdNen3a93AWCMZc557R0A7oY3XYCQ6AKERBcgJLoAIdEFCIkuQOgT/DkX3x4cq+wAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABcUlEQVR4nO3aMU4CURRA0RkhYMNOCHvS3bkfEldhtDCRirGyFDDKJcg57X+ZvOrm52fGaZoGABp3l14A4JaILkBIdAFCogsQEl2AkOgChOaHDrfbrf/JAH5ovV6P35256QKEDt50v7w/Pw373duZVwG4buNsMaw2DwdnTorufvc67D9e/mQpgH9rtjw64nkBICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6AKH5KUPjbDGMs+W5dwG4bvP74yOnfGe1efz1LgAMwzhN06V3ALgZ3nQBQqILEBJdgJDoAoREFyAkugChT4CSFx5zJZLBAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABeElEQVR4nO3avU3DYBRAUQelipNNvBliBkZgCCQm8gAIBcEWpqIjP0jhosA57XvFq64+WV4tyzIA0Lj57QMA/hPRBQiJLkBIdAFCogsQEl2A0PrYcJ5n/5MBfNM0TatDMy9dgNDRl+6n+7vb4f11/9O3AFy1zTgOD49PR3fOiu7b/mXYPz9f4iaAP2vc7k7u+LwAEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgND6nKXNuB3G3e6nbwG4auN2e3JntSzLweE8z4eHAHxpmqbVodnR6AJwWb7pAoREFyAkugAh0QUIiS5ASHQBQh+I4B1ndjYPqAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdElEQVR4nO3aMU7DUBBAQQeliM1VfEcKqFJwOl8BkSiHMBUdSUCChwIz7W6x1dOX5c26rgMAjbvfPgDgPxFdgJDoAoREFyAkugAh0QUIbS8Nl2XxPxnAF83zvDk389IFCF186b7bPz0Pp+Ppp28BuGm7cTc87h8u7nwqusfDcXh9OXzLUQB/1TSNV3d8XgAIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5AaPuZpXEch+l++ulbAG7aNI1Xdzbrup4dLstyfgjAh+Z53pybXYwuAN/LN12AkOgChEQXICS6ACHRBQiJLkDoDSpqHWveIwc5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABeUlEQVR4nO3aO07DQBRAUQfFkQJb8UYo2BYsioJNeA1I0EHoTUVHPkhwUeCc9o2sV12NRl4tyzIA0Lj47QUA/hPRBQiJLkBIdAFCogsQEl2A0PrQcJ5n/5MBfNE0Tat9MzddgNDBm+6Hh/u74W33/NO7AJy19bgdrm9uD5855UO73dPw+vL4LUsB/FXj5vLoGc8LACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQiJLkBIdAFCogsQEl2AkOgChEQXICS6ACHRBQitTzk0jtth3Fz99C4AZ20zbo+eWS3Lsnc4z/P+IQCfmqZptW92MLoAfC9vugAh0QUIiS5ASHQBQqILEBJdgNA7a7Idc7Bl4jMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdklEQVR4nO3aO07DUBBAUQelic1SvEMqCgoKOpbmHSB+qzAVHfkgJRcB57QzxVRXT5Y367oOADSufvoAgP9EdAFCogsQEl2AkOgChEQXILQ9NFyWxf9kAN80z/Nm38xLFyB08KX76fbmbnh/fb/0LQC/2m7cDQ+P9wd3Toru68vb8Pz0fJajAP6qaRqP7vi8ABASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYDQ9pSlcdwN0/V06VsAfrVxGo/ubNZ13TtclmX/EIAvzfO82Tc7GF0Azss3XYCQ6AKERBcgJLoAIdEFCIkuQOgDOjgdae3JXX4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABZklEQVR4nO3aMU4DMRBAUe9qkThMjgD3l6hzlZAOU1GSLAJ+BHmv9RRTfVmWlznnAKCx3noBgHsiugAh0QUIiS5ASHQBQqILENouHR6PR//JAL7ocDgsn5256QKELt50PzyuL2Mdr7+9C8CfNsc2zm9PF2d2RXcdp7Eupx9ZCuC/mvN6Uj0vAIREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyC07RmaYxtz7hoFuFtzPFyd2VXS89vzt5cBYIxlznnrHQDuhjddgJDoAoREFyAkugAh0QUIiS5A6B2uhRm7O9RsHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdUlEQVR4nO3asU0DQRBA0TNydOdSrjwCMkogJKCtqwCwTBdHRIaNkfBHhvfS2WCir9VqN+u6DgA0bn57AYD/RHQBQqILEBJdgJDoAoREFyC0PTVclsV/MoBvmud5c2zmpgsQOnnT/XB3fzsc3g6X3gXgqo3jODw+PJ08c1Z094f98PL6/CNLAfxV07T78oznBYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKEtuccmsZp2E27S+8CcNWmMzq5Wdf16HBZluNDAD41z/Pm2OxkdAH4Wd50AUKiCxASXYCQ6AKERBcgJLoAoXdJfh1qcyTSdQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABcklEQVR4nO3aMU5CQRRA0f/94AJYB7oPXbSrIHEbRi2wIN/KUsAolyDntPOKV91MJjPO8zwA0Lg59wIA10R0AUKiCxASXYCQ6AKERBcgtNh3uNls/CcD+KH1ej1+d+amCxDae9P98vL8NOw+3k+9C8BFG6flsLp72DtzVHR327dht339k6UA/qtxWh6c8bwAEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgJDoAoREFyAkugAh0QUIiS5ASHQBQqILEBJdgNDimKFxWg7jdHvqXQAu2rhYHpw5Krqr+8dfLwPAMIzzPJ97B4Cr4U0XICS6ACHRBQiJLkBIdAFCogsQ+gTxsBcO6kGbmgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAV0AAABGCAYAAABv7kdbAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/NK7nSAAAACXBIWXMAAAsTAAALEwEAmpwYAAABdUlEQVR4nO3aMU5CQRRA0f8/dsoG2AANO3NfuiFaE2NsXAJK8q0sRYxyiXJOO6941c1kMuM8zwMAjencCwBcEtEFCIkuQEh0AUKiCxASXYDQ1aHD7XbrPxnAN202m/GzMzddgNDBm+6Hl4fbYf/6fOpdAP60cboeVuu7gzNHRfdt9zTsd4+/sRPAvzUull/OeF4ACIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQEh0AUKiCxASXYCQ6AKERBcgJLoAIdEFCIkuQOjqmKFpcTNMi+WpdwH408bFzZczR0V3tb7/8TIADMM4z/O5dwC4GN50AUKiCxASXYCQ6AKERBcgJLoAoXcFAxdmukGqZQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# save the input_palettes to a temp file for prediction\n",
    "\n",
    "print('Original palettes: ')\n",
    "pred_file_path = 'Data_color_pred/color_corpus_pred.txt'\n",
    "\n",
    "PROJECT_PATH = Config['project_path']\n",
    "bin_range = Config['bin_range']\n",
    "\n",
    "with open(os.path.join(PROJECT_PATH, pred_file_path), 'w') as f:\n",
    "    line = '\"'\n",
    "    for volumn in volumns:\n",
    "        draw_palette(input_palettes[volumn])\n",
    "        for c in input_palettes[volumn]:\n",
    "            lab = rgb_to_lab(c)\n",
    "            lab_bins = f'{math.floor(lab[0]/bin_range)}_{math.floor(lab[1]/bin_range)}_{math.floor(lab[2]/bin_range)}'\n",
    "            line += f'{lab_bins} '\n",
    "        line += '; '\n",
    "    f.write(f'{line[:len(line) - 3]}\"\\n')\n",
    "\n",
    "print('Mask position: 1 denotes mask')\n",
    "print(maskColors)\n",
    "max_palette_length = Config['max_palette_length']\n",
    "mask_positions = []\n",
    "position = 0\n",
    "\n",
    "for v in range(len(volumns)):\n",
    "    pi = 0\n",
    "    for m in ast.literal_eval(maskColors[volumns[v]]):\n",
    "        if m == 1:\n",
    "            mask_positions.append(position+pi)\n",
    "        pi +=1\n",
    "    position += max_palette_length[v] + 1  # add 1 position of SEP\n",
    "\n",
    "Config_pred = Config.copy()\n",
    "Config_pred['batch_size'] = 1\n",
    "Config_pred['mask_position'] = mask_positions   # mask specified colors\n",
    "Config_pred['corpus_file_path'] = os.path.join(PROJECT_PATH, pred_file_path)\n",
    "\n",
    "sample_id = 0\n",
    "\n",
    "dataset = DataGenerator(Config_pred)\n",
    "batch_x,  batch_mlm_mask, batch_mcc_mask, origin_x, batch_segment, batch_padding_mask = dataset[sample_id]\n",
    "# print(f'original sequence: {dataset.corpus.token_id_to_word_list(list(origin_x[0]))}')\n",
    "# print(f'masked sequence: {dataset.corpus.token_id_to_word_list(list(batch_x[0]))}')\n",
    "\n",
    "mlm_predict, output_emb = re_model((batch_x, batch_mlm_mask, batch_segment), training=False)\n",
    "\n",
    "N = 10\n",
    "\n",
    "# print(f'original id: {dataset.corpus.token_id_to_word_list([origin_x[0][mask_positions[0]]])}')\n",
    "# print(f'predicted ids: {dataset.corpus.token_id_to_word_list(list(np.argsort(mlm_predict[0][mask_positions[0]])[::-1][:N]))}')\n",
    "\n",
    "print('Recommended results: ')\n",
    "\n",
    "batch_mlm_mask = tf.cast(batch_mlm_mask, dtype=tf.int32)\n",
    "index = tf.where(batch_mlm_mask == 1)\n",
    "# x_predict = tf.math.argmax(mlm_predict, axis=-1) # top1\n",
    "x_predict = tf.argsort(mlm_predict, axis=-1, direction='DESCENDING') # topn    \n",
    "x_predict = tf.gather_nd(x_predict, index)\n",
    "x_real = tf.gather_nd(origin_x, index)\n",
    "x_predict = x_predict.numpy()\n",
    "x_real = x_real.numpy()\n",
    "\n",
    "for p in range(len(x_predict)):\n",
    "    pred = []\n",
    "    for i in range(N):\n",
    "        pred.append(x_predict[p][i])\n",
    "    # check GT in predicted colors\n",
    "    if pred:\n",
    "        for pr in pred:\n",
    "            c = dataset.corpus.token_id_to_word_list([pr])\n",
    "            lab = c[0].split('_')\n",
    "            bin_bias = 0.5\n",
    "            rgb = range0to255(lab_to_rgb([(float(lab[0])+bin_bias)*bin_range, (float(lab[1])+bin_bias)*bin_range, (float(lab[2])+bin_bias)*bin_range]))\n",
    "            # print(rgb)\n",
    "            draw_palette([rgb])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f50169-c360-426c-9906-2a32b8a5c4ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": false,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
