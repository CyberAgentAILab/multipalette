{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a598a45-7588-4524-a357-6086705513ba",
   "metadata": {},
   "source": [
    "### This is the pre-training of color representation model\n",
    "- It takes 5-10mins on GPU (Tesla T4 * 1) within 100 epochs for one time training\n",
    "  (with batch-size=2048 in modelConfig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c98aa847-681b-4aee-b434-e09028155b11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/s12497/workspace/forShare/crello_color_recomm\n"
     ]
    }
   ],
   "source": [
    "%cd ../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2176a5ab-f5c1-4c32-97ef-b99a1556866b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import src.modeling as modeling\n",
    "from src.dataGenerator import DataGenerator\n",
    "from src.modelConfig import Config\n",
    "\n",
    "from datetime import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a63f47ed-5459-4f5f-bb3d-43c45dd73e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_pretrain_task_accuracy(mlm_predict, batch_mlm_mask, origin_x):\n",
    "\n",
    "    batch_mlm_mask = tf.cast(batch_mlm_mask, dtype=tf.int32)\n",
    "    index = tf.where(batch_mlm_mask == 1)\n",
    "    x_predict = tf.math.argmax(mlm_predict, axis=-1) # top1\n",
    "    x_predict = tf.gather_nd(x_predict, index)\n",
    "    x_real = tf.gather_nd(origin_x, index)\n",
    "    mlm_accuracy = tf.keras.metrics.Accuracy()\n",
    "    mlm_accuracy.update_state(x_predict, x_real)\n",
    "    mlm_accuracy = mlm_accuracy.result().numpy()\n",
    "\n",
    "    return mlm_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "90846b68-b1ea-4857-ad2c-a5bc1c71f250",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, step 292, loss 0.6399, mlm_loss 0.6399, mlm_acc 0.1111\n",
      "Val: Epoch 0, step 35, loss 0.9824, mlm_loss 0.9824, mlm_acc 0.1250\n",
      "Epoch 1, step 292, loss 1.0544, mlm_loss 1.0544, mlm_acc 0.0968\n",
      "Val: Epoch 1, step 35, loss 0.5287, mlm_loss 0.5287, mlm_acc 0.1250\n",
      "Test: Epoch 1, step 34, loss 0.7219, mlm_loss 0.7219, mlm_acc 0.0952\n"
     ]
    }
   ],
   "source": [
    "# pretrain\n",
    "\n",
    "# training on CPU\n",
    "physical_devices = tf.config.experimental.list_physical_devices('CPU')\n",
    "assert len(physical_devices) > 0, \"Not enough CPU hardware devices available\"\n",
    "\n",
    "# training on GPU\n",
    "# physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "# assert len(physical_devices) > 0, \"Not enough GPU hardware devices available\"\n",
    "# tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "model = modeling.Bert(Config)\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=5e-4)\n",
    "loss_fn = modeling.BERT_Loss()\n",
    "dataset = DataGenerator(Config)\n",
    "checkpoint = tf.train.Checkpoint(model=model)\n",
    "checkpoint.restore(tf.train.latest_checkpoint(Config['Saved_Weight']))\n",
    "manager = tf.train.CheckpointManager(checkpoint, directory=Config['Saved_Weight'], max_to_keep=5)\n",
    "log_dir = os.path.join(Config['Log_Dir'], datetime.now().strftime(\"%Y-%m-%d\"))\n",
    "writer = tf.summary.create_file_writer(log_dir)\n",
    "\n",
    "\n",
    "# create the data for validation and test\n",
    "PROJECT_PATH = Config['Project_path']\n",
    "Config_val = Config.copy()\n",
    "Config_val['Corpus_File_Path'] = os.path.join(PROJECT_PATH, f'Data_color/color_corpus_lab_bins_16_val_sklearn.txt')\n",
    "dataset_val = DataGenerator(Config_val)\n",
    "\n",
    "Config_test = Config.copy()\n",
    "Config_test['Corpus_File_Path'] = os.path.join(PROJECT_PATH, f'Data_color/color_corpus_lab_bins_16_test_sklearn.txt')\n",
    "dataset_test = DataGenerator(Config_test)\n",
    "\n",
    "patience = 30\n",
    "best = math.inf\n",
    "wait = 0\n",
    "\n",
    "for n in range(1):\n",
    "    EPOCH = 2 # 100 is enough\n",
    "    for epoch in range(EPOCH):\n",
    "    #     print(f'dataset length: {len(dataset)}')\n",
    "        for step in range(len(dataset)):\n",
    "            batch_x, batch_mlm_mask, batch_mcc_mask, origin_x, batch_segment, batch_padding_mask = dataset[step]\n",
    "            with tf.GradientTape() as t:\n",
    "                mlm_predict, sequence_output = model((batch_x, batch_mlm_mask, batch_segment), training=True)\n",
    "\n",
    "                mlm_loss = loss_fn((mlm_predict, batch_mlm_mask, origin_x))\n",
    "                mlm_loss = tf.reduce_mean(mlm_loss)\n",
    "\n",
    "                loss = mlm_loss\n",
    "\n",
    "            gradients = t.gradient(loss, model.trainable_variables)\n",
    "            optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "\n",
    "            # get acc of random mask\n",
    "            mlm_acc = calculate_pretrain_task_accuracy(mlm_predict, batch_mlm_mask, origin_x)\n",
    "\n",
    "            if step == len(dataset) - 1 and epoch % 1 == 0:\n",
    "                print(\n",
    "                    'Epoch {}, step {}, loss {:.4f}, mlm_loss {:.4f}, mlm_acc {:.4f}'.format(\n",
    "                        epoch, step, loss.numpy(),\n",
    "                        mlm_loss.numpy(),\n",
    "                        mlm_acc,\n",
    "                        ))\n",
    "\n",
    "        for val_step in range(len(dataset_val)):\n",
    "            val_batch_x, val_batch_mlm_mask, val_batch_mcc_mask, val_origin_x, val_batch_segment, val_batch_padding_mask = dataset_val[val_step]\n",
    "            val_mlm_predict, val_sequence_output = model((val_batch_x, val_batch_mlm_mask, val_batch_segment), training=False)\n",
    "\n",
    "            val_mlm_loss = loss_fn((val_mlm_predict, val_batch_mlm_mask, val_origin_x))\n",
    "            val_mlm_loss = tf.reduce_mean(val_mlm_loss)\n",
    "\n",
    "            # get acc of random mask\n",
    "            val_mlm_acc = calculate_pretrain_task_accuracy(val_mlm_predict, val_batch_mlm_mask, val_origin_x)\n",
    "\n",
    "            val_loss = val_mlm_loss\n",
    "\n",
    "            if val_step == len(dataset_val) - 1 and epoch % 1 == 0:\n",
    "                print(\n",
    "                    'Val: Epoch {}, step {}, loss {:.4f}, mlm_loss {:.4f}, mlm_acc {:.4f}'.format(\n",
    "                        epoch, val_step, val_loss.numpy(),\n",
    "                        val_mlm_loss.numpy(),\n",
    "                        val_mlm_acc,\n",
    "                        ))\n",
    "\n",
    "        path = manager.save(checkpoint_number=epoch)\n",
    "\n",
    "        # early stopping\n",
    "        wait += 1\n",
    "        if val_loss < best:\n",
    "            best = val_loss\n",
    "            wait = 0\n",
    "        if wait >= patience:\n",
    "            break\n",
    "\n",
    "    Config['Mask_Rate'] = 0\n",
    "    for test_step in range(len(dataset_test)):\n",
    "        test_batch_x, test_batch_mlm_mask, test_batch_mcc_mask, test_origin_x, test_batch_segment, test_batch_padding_mask = dataset_test[test_step]\n",
    "        test_mlm_predict, test_sequence_output = model((test_batch_x, test_batch_mlm_mask, test_batch_segment), training=False)\n",
    "\n",
    "        test_mlm_loss = loss_fn((test_mlm_predict, test_batch_mlm_mask, test_origin_x))\n",
    "        test_mlm_loss = tf.reduce_mean(test_mlm_loss)\n",
    "\n",
    "        # get acc of random mask\n",
    "        test_mlm_acc = calculate_pretrain_task_accuracy(test_mlm_predict, test_batch_mlm_mask, test_origin_x)\n",
    "\n",
    "        test_loss = test_mlm_loss\n",
    "\n",
    "        if test_step == len(dataset_test) - 1:\n",
    "            print(\n",
    "                'Test: Epoch {}, step {}, loss {:.4f}, mlm_loss {:.4f}, mlm_acc {:.4f}'.format(\n",
    "                    epoch, test_step, test_loss.numpy(),\n",
    "                    test_mlm_loss.numpy(),\n",
    "                    test_mlm_acc,\n",
    "                    ))\n",
    "\n",
    "    # model.save(f'model/bert_{representation}_{n}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d30700-510b-4dff-9e99-cb775b6dd2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
